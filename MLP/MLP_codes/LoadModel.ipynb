{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from NeuralNetworkProj.Layers.ActivationFunctionLayers import ReLu,Sigmoid,Softmax\n",
    "from NeuralNetworkProj.Layers.LinearLayer import LinearLayer\n",
    "from NeuralNetworkProj.Layers.LossFuntionLayers import CrossEntropy\n",
    "from NeuralNetworkProj.Utilities.DataTools import get_mnist_data,convert_dataset_numpy_array\n",
    "from NeuralNetworkProj.Utilities.InitalizationFunctions import normal_initializer\n",
    "from NeuralNetworkProj.Optim.LearningRate import LearningRate\n",
    "from NeuralNetworkProj.Optim.Optimizer import NaiveUpdator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self,model,updator) -> None:\n",
    "        self.model=model\n",
    "        self.updator=updator\n",
    "    def __call__(self, x):\n",
    "        input_=x\n",
    "        for layer in self.model:\n",
    "            input_=layer(input_)\n",
    "        return input_\n",
    "\n",
    "    def forward(self,x): # No recording method\n",
    "        input_=x\n",
    "        for layer in self.model:\n",
    "            input_=layer.forward(input_)\n",
    "        return input_\n",
    "\n",
    "    def backward(self,grad):\n",
    "        for layer in self.model[::-1]:\n",
    "            grad=layer.backward(grad)\n",
    "        return grad\n",
    "    def Update(self):\n",
    "        for layer in self.model:\n",
    "            if not layer.require_update:\n",
    "                continue\n",
    "            seters=layer.parameter_seters()\n",
    "            for name in layer.parameter_names():\n",
    "                var_before=getattr(layer,name)\n",
    "                grad_before=getattr(layer,name+\"_grad\")\n",
    "                seters[name](self.updator(getattr(layer,name),getattr(layer,name+\"_grad\")))\n",
    "                assert(np.allclose(getattr(layer,name),self.updator(var_before,grad_before)))\n",
    "    \n",
    "    def predict_prob(self,x):\n",
    "        input_=x\n",
    "        for layer in self.model:\n",
    "            input_=layer.forward(input_) # avoid record data\n",
    "        return input_\n",
    "    \n",
    "    def predict_label(self,x):\n",
    "        prob=self.predict_prob(x)\n",
    "        return np.argsort(prob,axis=1)[:,-1]\n",
    "\n",
    "    def save_model(self,path):\n",
    "        step=0\n",
    "        folder=Path(path)\n",
    "        if not folder.exists():\n",
    "            folder.mkdir(parents=True)\n",
    "        for layer in self.model:\n",
    "            if layer.require_update:\n",
    "                layer.save_model(str(folder/(\"layer_\"+str(step))))\n",
    "            step+=1\n",
    "    def load_model(self,path):\n",
    "        step=0\n",
    "        for layer in self.model:\n",
    "            if not layer.require_update:\n",
    "                step+=1\n",
    "                continue\n",
    "            seters=layer.parameter_seters()\n",
    "            for name in layer.parameter_names():\n",
    "                temp=np.load(os.path.join(path,\"layer_{}_{}.npy\".format(step,name)))\n",
    "                seters[name](temp)\n",
    "            step+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define network structure\n",
    "in_feature=784\n",
    "hidden_feature_1=40\n",
    "hidden_feature_2=20\n",
    "out_feature=10\n",
    "\n",
    "bias_option=True\n",
    "\n",
    "netowrk=[\n",
    "    LinearLayer(input_size=in_feature,output_size=hidden_feature_1,initialization=normal_initializer,bias=bias_option),\n",
    "    ReLu(),\n",
    "    LinearLayer(input_size=hidden_feature_1,output_size=hidden_feature_2,initialization=normal_initializer,bias=bias_option),\n",
    "    Sigmoid(),\n",
    "    LinearLayer(input_size=hidden_feature_2,output_size=out_feature,initialization=normal_initializer,bias=bias_option),\n",
    "    Softmax()\n",
    "]\n",
    "\n",
    "loss_criteria=CrossEntropy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(netowrk,NaiveUpdator(LearningRate(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_model(\"result/model_epoch200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data=get_mnist_data()\n",
    "trn_data_label=convert_dataset_numpy_array(train_data)\n",
    "# trn_data_label[0]=trn_data_label[0].reshape(-1,784)\n",
    "\n",
    "tst_data_label=convert_dataset_numpy_array(test_data)\n",
    "# tst_data_label[0]=tst_data_label[0].reshape(-1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_data_label[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=model.predict_prob(trn_data_label[0].reshape(-1,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7578"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argsort(prob,axis=1)[:,-1]==trn_data_label[1].ravel())/len(trn_data_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob2=model.predict_prob(tst_data_label[0].reshape(-1,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7622"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argsort(prob2,axis=1)[:,-1]==tst_data_label[1].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "709908c57e4fe06be2030c33e68a5897e38c119e807fb99702f3b3b73d7ee1ee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('experiments': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
