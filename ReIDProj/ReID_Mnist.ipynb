{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yju6GyB1GWhm"
      },
      "source": [
        "[File colab link](https://colab.research.google.com/drive/1bXbzJgUoGeIM_7EMgnh6p-UsvAkRY8Tj#scrollTo=31EWlxEpDA_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "lB4HLpu7CIiT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import traceback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "GGNfcuXTCoAr"
      },
      "outputs": [],
      "source": [
        "DEBUG=True\n",
        "batch_size=128\n",
        "shuffle_flag=False if DEBUG else False\n",
        "train_data=torchvision.datasets.MNIST(\"./data\",train=True,download=True,transform=torchvision.transforms.ToTensor())\n",
        "test_data=torchvision.datasets.MNIST(\"./data\",train=False,download=True,transform=torchvision.transforms.ToTensor())# Warning: ToTensor will divide the original data by 255\n",
        "train_loader=DataLoader(train_data,batch_size=batch_size,shuffle=shuffle_flag) \n",
        "test_loader=DataLoader(test_data,batch_size=batch_size,shuffle=shuffle_flag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "31EWlxEpDA_b",
        "outputId": "50d94131-fb5d-4653-fd6e-78157ab50c79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'digit 5')"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(train_data.data[0].detach().numpy(),cmap=\"gray\")\n",
        "plt.title(\"digit {}\".format(train_data.targets[0].detach().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6_YBVYvPbAj"
      },
      "source": [
        "## Create network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nKYuvz9tPcnZ"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self,in_feature_2d,out_feature):\n",
        "    self.in_feature_2d=in_feature_2d\n",
        "    super(ConvNet,self).__init__()\n",
        "    self.layer_2d=[]\n",
        "    self. _set_network(in_feature_2d,out_feature) # Internal protected method\n",
        "\n",
        "  def _set_network(self,in_feature_2d,out_feature):\n",
        "    self.conv1=nn.Conv2d(in_channels=1,out_channels=16,kernel_size=(5,5),stride=1,padding=\"same\")\n",
        "    self.layer_2d.append(self.conv1)\n",
        "\n",
        "    self.act1=nn.ReLU()\n",
        "    self.layer_2d.append(self.act1)\n",
        "\n",
        "    self.pooling1=nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
        "    self.layer_2d.append(self.pooling1)\n",
        "\n",
        "    self.conv2=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=(3,3),padding=\"same\")\n",
        "    self.layer_2d.append(self.conv2)\n",
        "\n",
        "    self.act2=nn.ReLU()\n",
        "    self.layer_2d.append(self.act2)\n",
        "\n",
        "    self.pooling2=nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
        "    self.layer_2d.append(self.pooling2)\n",
        "\n",
        "    self.conv3=nn.Conv2d(in_channels=32,out_channels=32,kernel_size=(3,3),padding=\"same\")\n",
        "    self.layer_2d.append(self.conv3)\n",
        "\n",
        "    self.act3=nn.ReLU()\n",
        "    self.layer_2d.append(self.act3)\n",
        "\n",
        "    self.pooling3=nn.MaxPool2d(kernel_size=(7,7)) # global max pooling with pooling size of the input\n",
        "    self.layer_2d.append(self.pooling3)\n",
        "\n",
        "    self.featureFC=nn.Linear(in_features=32,out_features=2,bias=True)\n",
        "    self.outputFC=nn.Linear(in_features=2,out_features=out_feature,bias=True)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    feature=self.feature_extraction(x)\n",
        "    return self.outputFC(feature)\n",
        "  \n",
        "  def feature_extraction(self,x):\n",
        "    input=x\n",
        "    for layer in self.layer_2d:\n",
        "      output=layer(input)\n",
        "      input=output\n",
        "    output=self.featureFC(output.squeeze())\n",
        "    return output\n",
        "  \n",
        "  def predict_prob(self,x):\n",
        "    output=self.forward(x)\n",
        "    return output.softmax(dim=1) # apply softmax to each row, each batch\n",
        "  \n",
        "  def predict(self,x):\n",
        "    prob=self.predict_prob(x)\n",
        "    return prob.argmax(dim=1)\n",
        "\n",
        "class MLPNet(nn.Module):\n",
        "  def __init__(self,in_feature_2d,out_feature):\n",
        "    self.in_feature_2d=in_feature_2d\n",
        "    super(MLPNet,self).__init__()\n",
        "    self.layers=nn.Sequential([\n",
        "    nn.Linear(in_features=in_feature_2d[0]*in_feature_2d[1],out_features=200),\n",
        "    nn.Linear(in_features=200,out_features=200),\n",
        "    nn.Linear(in_features=200,out_features=10)\n",
        "    ])\n",
        "\n",
        "  \n",
        "  def forward(self,x):\n",
        "    return self.layers(x)\n",
        "  \n",
        "  def predict_prob(self,x):\n",
        "    output=self.forward(x)\n",
        "    return output.softmax(dim=1) # apply softmax to each row, each batch\n",
        "  \n",
        "  def predict(self,x):\n",
        "    prob=self.predict_prob(x)\n",
        "    return prob.argmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qUyr-RfnrtG9"
      },
      "outputs": [],
      "source": [
        "input_size_2d=np.array(train_data.data[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-M06ac4xrRvV"
      },
      "outputs": [],
      "source": [
        "model=ConvNet(input_size_2d,10)\n",
        "EPOCHES=20\n",
        "learning_rate=0.01\n",
        "momentum=0.5\n",
        "optimizer=optim.SGD(model.parameters(),lr=learning_rate,momentum=momentum)\n",
        "loss_func=nn.CrossEntropyLoss()\n",
        "# model_MLP=ConvNet(input_size_2d,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6y-DVlvEs1iX"
      },
      "outputs": [],
      "source": [
        "# lr=0.1\n",
        "# EPOCHES=20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XzLz7sxWsQO-"
      },
      "outputs": [],
      "source": [
        "# optimizer=optim.SGD(model_MLP.parameters(),lr=lr)\n",
        "# loss_func=nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6LW1pp6Ys5Fe"
      },
      "outputs": [],
      "source": [
        "def train( model, train_loader, test_loader, optimizer, loss_func, EPOCHES, device=torch.device(\"cpu\")):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    train_loss_recorder = []\n",
        "    lr_recorder = []\n",
        "    for epoch in range(EPOCHES):\n",
        "        avg_loss = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # clear all grad to avoid cumulation of grad\n",
        "            output = model(data)\n",
        "            loss_val = loss_func(output, target)\n",
        "            avg_loss += loss_val.item()\n",
        "            loss_val.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(\n",
        "                    \"Train Epoch:{}/{} [{}/{} ({:.0f}%)] \\t Loss: {:.6f}\\r\".format(\n",
        "                        epoch + 1,\n",
        "                        EPOCHES,\n",
        "                        batch_idx * len(data),\n",
        "                        len(train_loader.dataset),\n",
        "                        100 * (batch_idx / len(train_loader)),\n",
        "                        loss_val.item(),\n",
        "                    ),\n",
        "                    end=\"\",\n",
        "                )\n",
        "\n",
        "\n",
        "        avg_loss = avg_loss / (len(train_loader))\n",
        "        train_loss_recorder.append([epoch, avg_loss])\n",
        "        lr_recorder.append([epoch, optimizer.param_groups[0][\"lr\"]])\n",
        "        if epoch % 20 ==0:\n",
        "            print(\n",
        "                \"Train Epoch:{}/{} \\t Average Loss: {:.6f}\\r\".format(\n",
        "                    epoch+1, EPOCHES, avg_loss\n",
        "                )\n",
        "            )\n",
        "            torch.save(model.state_dict(), \"model_epoch_{}.pth\".format(epoch))\n",
        "            torch.save(optimizer.state_dict(), \"optimizer_epoch_{}.pth\".format(epoch))\n",
        "    torch.save(model.state_dict(), \"model_epoch_{}.pth\".format(epoch))\n",
        "    torch.save(optimizer.state_dict(), \"optimizer_epoch_{}.pth\".format(epoch))\n",
        "    return {\"loss\": {\"train_loss\": train_loss_recorder}, \"lr\": lr_recorder}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO5_9-_fuNfn",
        "outputId": "438cc891-67cb-42d0-8b24-74a68740442b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch:1/20 \t Average Loss: 2.310337ss: 2.279210\n",
            "Train Epoch:20/20 [51200/60000 (85%)] \t Loss: 0.473676\r"
          ]
        }
      ],
      "source": [
        "recorded_message=train(model,train_loader,test_loader,optimizer,loss_func,EPOCHES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pSKwUIMg4HvJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train_loss': [[0, 2.31033702242349],\n",
              "  [1, 2.0846336012455953],\n",
              "  [2, 1.4363949898717754],\n",
              "  [3, 1.0971023685642396],\n",
              "  [4, 0.9209546910674333],\n",
              "  [5, 0.8030417114178509],\n",
              "  [6, 0.717327441233816],\n",
              "  [7, 0.6513753704933215],\n",
              "  [8, 0.5947400445877108],\n",
              "  [9, 0.547595380402323],\n",
              "  [10, 0.5079367309808731],\n",
              "  [11, 0.4744971130194186],\n",
              "  [12, 0.4464239339266759],\n",
              "  [13, 0.42221564670869793],\n",
              "  [14, 0.40090636192544943],\n",
              "  [15, 0.3825492435839893],\n",
              "  [16, 0.3659070631080091],\n",
              "  [17, 0.3509719864105873],\n",
              "  [18, 0.33698477786677733],\n",
              "  [19, 0.32360204209142657]]}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "recorded_message[\"loss\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TestTools():\n",
        "    registered_service={}\n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "    @classmethod\n",
        "    def accuracy_rate(cls,model,data,targets):\n",
        "        cls.registered_service[\"accuracy\"]=cls.accuracy_rate # not work as hope\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            result=model.predict(data.reshape(-1,1,28,28).float())\n",
        "        return (torch.sum(result==targets).item()/len(train_data))\n",
        "    @classmethod\n",
        "    def loss(cls,model,loss_func,data,targets):\n",
        "        cls.registered_service[\"loss\"]=cls.loss\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            data=data.reshape(-1,1,28,28).float()\n",
        "            output=model(data)\n",
        "            loss_val=loss_func(output,targets)\n",
        "        return loss_val.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(model, data_loader, loss_func, device=torch.device(\"cpu\")):\n",
        "  model.eval()\n",
        "  test_losses=[]\n",
        "  test_loss=0\n",
        "  correct=0\n",
        "  with torch.no_grad():\n",
        "    for data,target in data_loader:\n",
        "      output=model(data)\n",
        "      test_loss+=loss_func(output,target).item()\n",
        "      pred=output.softmax(dim=1).data.max(1,keepdim=True)[1]\n",
        "      correct+=pred.eq(target.data.view_as(pred)).sum()\n",
        "    test_loss/=len(data_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "    print(\"\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
        "        test_loss,correct,len(data_loader.dataset),100.* correct / len(data_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  result=model.predict_prob(train_data.data.reshape(-1,1,28,28).float())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8872833333333333\n",
            "0.3798563480377197\n"
          ]
        }
      ],
      "source": [
        "print(TestTools.accuracy_rate(model,train_data.data/255,train_data.targets))\n",
        "print(TestTools.loss(model,loss_func,train_data.data[:64]/255,train_data.targets[:64]))\n",
        "# print(test(model,train_loader,loss_func))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "output=model(train_data.data.reshape(-1,1,28,28).float())\n",
        "pred=output.softmax(dim=1).argmax(dim=1,keepdim=True)\n",
        "pred2=output.softmax(dim=1).data.max(1,keepdim=True)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(44921)\n",
            "tensor(44921)\n"
          ]
        }
      ],
      "source": [
        "print(torch.sum(pred==train_data.targets.view_as(pred)))\n",
        "print(torch.sum(pred2==train_data.targets.view_as(pred2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "correct=0\n",
        "total_samples=0\n",
        "step=0\n",
        "with torch.no_grad():\n",
        "    for data,target in train_loader:\n",
        "        total_samples+=len(data)\n",
        "        output=model(data)\n",
        "        pred=output.softmax(dim=1).data.max(1,keepdim=True)[1]\n",
        "        correct+=pred.eq(target.data.view_as(pred)).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.all(train_loader.dataset.data[0]==train_data.data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "list is not a Module subclass",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10224/1836851031.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_MLP2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMLPNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_size_2d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\20211575\\Downloads\\Workspace\\ProjectComputerVisionAnd3DImageProcessing\\ReIDProj\\model_epoch_4.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10224/290775002.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_feature_2d, out_feature)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_feature_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0min_feature_2d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLPNet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     self.layers=nn.Sequential([\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0min_feature_2d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0min_feature_2d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_item_by_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36madd_module\u001b[1;34m(self, name, module)\u001b[0m\n\u001b[0;32m    375\u001b[0m         \"\"\"\n\u001b[0;32m    376\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m             raise TypeError(\"{} is not a Module subclass\".format(\n\u001b[0m\u001b[0;32m    378\u001b[0m                 torch.typename(module)))\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: list is not a Module subclass"
          ]
        }
      ],
      "source": [
        "model_MLP2=MLPNet(input_size_2d,10).load_state_dict(torch.load(r\"C:\\Users\\20211575\\Downloads\\Workspace\\ProjectComputerVisionAnd3DImageProcessing\\ReIDProj\\model_epoch_4.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ReID-Mnist.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
